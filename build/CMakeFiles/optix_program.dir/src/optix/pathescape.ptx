//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-30672275
// Cuda compilation tools, release 11.5, V11.5.119
// Based on NVVM 7.0.1
//

.version 7.5
.target sm_52
.address_size 64

	// .globl	__raygen__rg
.const .align 8 .b8 params[32];
.global .align 4 .f32 _ZZN4tcnn19gaussian_cdf_approxEffE20MAGIC_SIGMOID_FACTOR = 0f3F4ABDDD;
.global .align 4 .f32 _ZZN4tcnn30gaussian_cdf_approx_derivativeEffE20MAGIC_SIGMOID_FACTOR = 0f3F4ABDDD;
.global .align 4 .b8 _ZZN3ngp5sobolEjjE10directions[640] = {0, 0, 0, 128, 0, 0, 0, 64, 0, 0, 0, 32, 0, 0, 0, 16, 0, 0, 0, 8, 0, 0, 0, 4, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 128, 0, 0, 0, 64, 0, 0, 0, 32, 0, 0, 0, 16, 0, 0, 0, 8, 0, 0, 0, 4, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 128, 0, 0, 0, 64, 0, 0, 0, 32, 0, 0, 0, 16, 0, 0, 0, 8, 0, 0, 0, 4, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 128, 0, 0, 0, 64, 0, 0, 0, 32, 0, 0, 0, 16, 0, 0, 0, 8, 0, 0, 0, 4, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 128, 0, 0, 0, 192, 0, 0, 0, 160, 0, 0, 0, 240, 0, 0, 0, 136, 0, 0, 0, 204, 0, 0, 0, 170, 0, 0, 0, 255, 0, 0, 128, 128, 0, 0, 192, 192, 0, 0, 160, 160, 0, 0, 240, 240, 0, 0, 136, 136, 0, 0, 204, 204, 0, 0, 170, 170, 0, 0, 255, 255, 0, 128, 0, 128, 0, 192, 0, 192, 0, 160, 0, 160, 0, 240, 0, 240, 0, 136, 0, 136, 0, 204, 0, 204, 0, 170, 0, 170, 0, 255, 0, 255, 128, 128, 128, 128, 192, 192, 192, 192, 160, 160, 160, 160, 240, 240, 240, 240, 136, 136, 136, 136, 204, 204, 204, 204, 170, 170, 170, 170, 255, 255, 255, 255, 0, 0, 0, 128, 0, 0, 0, 192, 0, 0, 0, 96, 0, 0, 0, 144, 0, 0, 0, 232, 0, 0, 0, 92, 0, 0, 0, 142, 0, 0, 0, 197, 0, 0, 128, 104, 0, 0, 192, 156, 0, 0, 96, 238, 0, 0, 144, 85, 0, 0, 104, 128, 0, 0, 156, 192, 0, 0, 238, 96, 0, 0, 85, 144, 0, 128, 128, 232, 0, 192, 192, 92, 0, 96, 96, 142, 0, 144, 144, 197, 0, 232, 104, 104, 0, 92, 156, 156, 0, 142, 238, 238, 0, 197, 85, 85, 128, 232, 0, 128, 192, 92, 0, 192, 96, 142, 0, 96, 144, 197, 0, 144, 104, 104, 0, 232, 156, 156, 0, 92, 238, 238, 0, 142, 85, 85, 0, 197, 0, 0, 0, 128, 0, 0, 0, 192, 0, 0, 0, 32, 0, 0, 0, 80, 0, 0, 0, 248, 0, 0, 0, 116, 0, 0, 0, 162, 0, 0, 0, 147, 0, 0, 128, 216, 0, 0, 64, 37, 0, 0, 224, 89, 0, 0, 208, 230, 0, 0, 8, 120, 0, 0, 12, 180, 0, 0, 2, 130, 0, 0, 5, 195, 0, 128, 143, 32, 0, 64, 71, 81, 0, 32, 234, 251, 0, 48, 217, 117, 0, 136, 133, 160, 0, 84, 78, 145, 0, 158, 231, 219, 0, 109, 219, 37, 128, 0, 128, 88, 192, 0, 64, 229, 32, 0, 224, 121, 80, 0, 208, 182, 248, 0, 8, 128, 116, 0, 12, 192, 162, 0, 2, 32, 147, 0, 5, 80, 0, 0, 0, 128, 0, 0, 0, 64, 0, 0, 0, 32, 0, 0, 0, 176, 0, 0, 0, 248, 0, 0, 0, 220, 0, 0, 0, 122, 0, 0, 0, 157, 0, 0, 128, 90, 0, 0, 192, 47, 0, 0, 96, 161, 0, 0, 176, 240, 0, 0, 136, 218, 0, 0, 196, 111, 0, 0, 98, 129, 0, 0, 187, 64, 0, 128, 135, 34, 0, 192, 201, 179, 0, 160, 101, 251, 0, 208, 178, 221, 0, 40, 2, 120, 0, 60, 11, 156, 0, 182, 15, 90, 0, 219, 13, 45, 128, 128, 135, 162, 64, 192, 201, 243, 32, 160, 101, 219, 176, 208, 178, 109, 248, 40, 2, 128, 220, 60, 11, 64, 122, 182, 15, 32, 157, 219, 13, 176};
.global .align 4 .u32 _ZZ12__raygen__rgE7N_PATHS = 32;
.global .align 4 .u32 _ZZ12__raygen__rgE9N_BOUNCES = 4;
.global .align 4 .b8 __cudart_i2opi_f[24] = {65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};

.visible .entry __raygen__rg()
{
	.local .align 4 .b8 	__local_depot0[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<121>;
	.reg .f32 	%f<712>;
	.reg .b32 	%r<858>;
	.reg .f64 	%fd<15>;
	.reg .b64 	%rd<318>;


	mov.u64 	%SPL, __local_depot0;
	add.u64 	%rd1, %SPL, 0;
	// begin inline asm
	call (%r128), _optix_get_launch_index_x, ();
	// end inline asm
	mov.u64 	%rd282, 0;
	ld.const.u64 	%rd99, [params];
	cvta.to.global.u64 	%rd100, %rd99;
	cvt.u64.u32 	%rd2, %r128;
	mul.wide.u32 	%rd101, %r128, 12;
	add.s64 	%rd102, %rd100, %rd101;
	ld.global.f32 	%f1, [%rd102];
	ld.global.f32 	%f2, [%rd102+4];
	ld.global.f32 	%f3, [%rd102+8];
	shl.b32 	%r1, %r128, 9;
	setp.eq.s32 	%p5, %r1, 0;
	mov.u64 	%rd286, -8846114313915602277;
	@%p5 bra 	$L__BB0_4;

	cvt.u64.u32 	%rd281, %r1;
	mov.u64 	%rd285, 1;
	mov.u64 	%rd284, -2720673578348880933;
	mov.u64 	%rd283, 6364136223846793005;

$L__BB0_2:
	and.b64  	%rd107, %rd281, 1;
	setp.eq.b64 	%p6, %rd107, 1;
	mul.lo.s64 	%rd108, %rd282, %rd283;
	add.s64 	%rd109, %rd108, %rd284;
	selp.b64 	%rd110, %rd283, 1, %p6;
	mul.lo.s64 	%rd285, %rd110, %rd285;
	selp.b64 	%rd282, %rd109, %rd282, %p6;
	add.s64 	%rd111, %rd283, 1;
	mul.lo.s64 	%rd284, %rd111, %rd284;
	mul.lo.s64 	%rd283, %rd283, %rd283;
	shr.u64 	%rd281, %rd281, 1;
	setp.ne.s64 	%p7, %rd281, 0;
	@%p7 bra 	$L__BB0_2;

	mul.lo.s64 	%rd286, %rd285, -8846114313915602277;

$L__BB0_4:
	add.s64 	%rd316, %rd282, %rd286;
	ld.const.u64 	%rd18, [params+24];
	ld.const.u64 	%rd112, [params+8];
	cvta.to.global.u64 	%rd19, %rd112;
	mov.u32 	%r831, 0;
	mov.f32 	%f172, 0f3F800000;
	mov.f32 	%f176, 0fBFC90FDA;
	mov.f32 	%f178, 0fB3A22168;
	mov.f32 	%f180, 0fA7C234C5;
	add.s64 	%rd22, %rd1, 24;
	mov.u32 	%r832, %r831;

$L__BB0_5:
	mul.lo.s64 	%rd113, %rd316, 6364136223846793005;
	add.s64 	%rd21, %rd113, -2720673578348880933;
	shr.u64 	%rd114, %rd316, 18;
	xor.b64  	%rd115, %rd114, %rd316;
	shr.u64 	%rd116, %rd115, 27;
	cvt.u32.u64 	%r137, %rd116;
	shr.u64 	%rd117, %rd316, 59;
	cvt.u32.u64 	%r138, %rd117;
	shf.r.wrap.b32 	%r139, %r137, %r137, %r138;
	shr.u32 	%r140, %r139, 9;
	or.b32  	%r141, %r140, 1065353216;
	mov.b32 	%f167, %r141;
	add.f32 	%f168, %f167, 0fBF800000;
	shr.u64 	%rd118, %rd21, 18;
	xor.b64  	%rd119, %rd118, %rd21;
	shr.u64 	%rd120, %rd119, 27;
	cvt.u32.u64 	%r142, %rd120;
	shr.u64 	%rd121, %rd21, 59;
	cvt.u32.u64 	%r143, %rd121;
	shf.r.wrap.b32 	%r144, %r142, %r142, %r143;
	shr.u32 	%r145, %r144, 9;
	or.b32  	%r146, %r145, 1065353216;
	mov.b32 	%f169, %r146;
	add.f32 	%f170, %f169, 0fBF800000;
	add.f32 	%f171, %f168, %f168;
	sub.f32 	%f4, %f172, %f171;
	add.f32 	%f173, %f170, 0fBF000000;
	mul.f32 	%f5, %f173, 0f40C90FDB;
	mul.f32 	%f174, %f5, 0f3F22F983;
	cvt.rni.s32.f32 	%r837, %f174;
	cvt.rn.f32.s32 	%f175, %r837;
	fma.rn.f32 	%f177, %f175, %f176, %f5;
	fma.rn.f32 	%f179, %f175, %f178, %f177;
	fma.rn.f32 	%f675, %f175, %f180, %f179;
	abs.f32 	%f7, %f5;
	setp.leu.f32 	%p8, %f7, 0f47CE4780;
	@%p8 bra 	$L__BB0_13;

	setp.eq.f32 	%p9, %f7, 0f7F800000;
	@%p9 bra 	$L__BB0_12;
	bra.uni 	$L__BB0_7;

$L__BB0_12:
	mov.f32 	%f183, 0f00000000;
	mul.rn.f32 	%f675, %f5, %f183;
	bra.uni 	$L__BB0_13;

$L__BB0_7:
	mov.b32 	%r6, %f5;
	bfe.u32 	%r148, %r6, 23, 8;
	add.s32 	%r7, %r148, -128;
	shl.b32 	%r149, %r6, 8;
	or.b32  	%r8, %r149, -2147483648;
	shr.u32 	%r9, %r7, 5;
	mov.u64 	%rd291, 0;
	mov.u32 	%r834, 0;
	mov.u64 	%rd289, __cudart_i2opi_f;
	mov.u64 	%rd290, %rd1;

$L__BB0_8:
	.pragma "nounroll";
	ld.global.nc.u32 	%r150, [%rd289];
	mad.wide.u32 	%rd124, %r150, %r8, %rd291;
	shr.u64 	%rd291, %rd124, 32;
	st.local.u32 	[%rd290], %rd124;
	add.s64 	%rd290, %rd290, 4;
	add.s64 	%rd289, %rd289, 4;
	add.s32 	%r834, %r834, 1;
	setp.ne.s32 	%p10, %r834, 6;
	@%p10 bra 	$L__BB0_8;

	st.local.u32 	[%rd22], %rd291;
	mov.u32 	%r151, 4;
	sub.s32 	%r12, %r151, %r9;
	mov.u32 	%r152, 6;
	sub.s32 	%r153, %r152, %r9;
	mul.wide.s32 	%rd125, %r153, 4;
	add.s64 	%rd126, %rd1, %rd125;
	ld.local.u32 	%r835, [%rd126];
	ld.local.u32 	%r836, [%rd126+-4];
	and.b32  	%r15, %r7, 31;
	setp.eq.s32 	%p11, %r15, 0;
	@%p11 bra 	$L__BB0_11;

	mov.u32 	%r154, 32;
	sub.s32 	%r155, %r154, %r15;
	shr.u32 	%r156, %r836, %r155;
	shl.b32 	%r157, %r835, %r15;
	add.s32 	%r835, %r156, %r157;
	mul.wide.s32 	%rd127, %r12, 4;
	add.s64 	%rd128, %rd1, %rd127;
	ld.local.u32 	%r158, [%rd128];
	shr.u32 	%r159, %r158, %r155;
	shl.b32 	%r160, %r836, %r15;
	add.s32 	%r836, %r159, %r160;

$L__BB0_11:
	and.b32  	%r161, %r6, -2147483648;
	shr.u32 	%r162, %r836, 30;
	shl.b32 	%r163, %r835, 2;
	or.b32  	%r164, %r162, %r163;
	shr.u32 	%r165, %r164, 31;
	shr.u32 	%r166, %r835, 30;
	add.s32 	%r167, %r165, %r166;
	neg.s32 	%r168, %r167;
	setp.eq.s32 	%p12, %r161, 0;
	selp.b32 	%r837, %r167, %r168, %p12;
	setp.ne.s32 	%p13, %r165, 0;
	xor.b32  	%r169, %r161, -2147483648;
	selp.b32 	%r170, %r169, %r161, %p13;
	selp.b32 	%r171, -1, 0, %p13;
	xor.b32  	%r172, %r164, %r171;
	shl.b32 	%r173, %r836, 2;
	xor.b32  	%r174, %r173, %r171;
	cvt.u64.u32 	%rd129, %r172;
	cvt.u64.u32 	%rd130, %r174;
	bfi.b64 	%rd131, %rd129, %rd130, 32, 32;
	cvt.rn.f64.s64 	%fd1, %rd131;
	mul.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f181, %fd2;
	setp.eq.s32 	%p14, %r170, 0;
	neg.f32 	%f182, %f181;
	selp.f32 	%f675, %f181, %f182, %p14;

$L__BB0_13:
	mul.f32 	%f193, %f4, %f4;
	sub.f32 	%f195, %f172, %f193;
	mov.f32 	%f192, 0f00000000;
	max.f32 	%f196, %f195, %f192;
	sqrt.rn.f32 	%f197, %f196;
	mul.f32 	%f198, %f675, %f675;
	mov.f32 	%f199, 0fBAB607ED;
	mov.f32 	%f200, 0f37CBAC00;
	fma.rn.f32 	%f201, %f200, %f198, %f199;
	mov.f32 	%f202, 0f3D2AAABB;
	fma.rn.f32 	%f203, %f201, %f198, %f202;
	mov.f32 	%f204, 0fBEFFFFFF;
	fma.rn.f32 	%f205, %f203, %f198, %f204;
	fma.rn.f32 	%f206, %f205, %f198, %f172;
	fma.rn.f32 	%f207, %f198, %f675, %f192;
	mov.f32 	%f208, 0f3C0885E4;
	mov.f32 	%f209, 0fB94D4153;
	fma.rn.f32 	%f210, %f209, %f198, %f208;
	mov.f32 	%f211, 0fBE2AAAA8;
	fma.rn.f32 	%f212, %f210, %f198, %f211;
	fma.rn.f32 	%f213, %f212, %f207, %f675;
	mov.u32 	%r213, 1;
	and.b32  	%r246, %r837, 1;
	setp.eq.b32 	%p15, %r246, 1;
	mov.u32 	%r212, 0;
	selp.f32 	%f214, %f206, %f213, %p15;
	selp.f32 	%f215, %f213, %f206, %p15;
	and.b32  	%r247, %r837, 2;
	setp.eq.s32 	%p16, %r247, 0;
	neg.f32 	%f216, %f214;
	selp.f32 	%f217, %f214, %f216, %p16;
	add.s32 	%r248, %r837, 1;
	and.b32  	%r249, %r248, 2;
	setp.eq.s32 	%p17, %r249, 0;
	neg.f32 	%f218, %f215;
	selp.f32 	%f219, %f215, %f218, %p17;
	mul.f32 	%f187, %f197, %f219;
	mul.f32 	%f188, %f197, %f217;
	mul.lo.s64 	%rd133, %rd21, 6364136223846793005;
	add.s64 	%rd316, %rd133, -2720673578348880933;
	mov.f32 	%f191, 0f5A0E1BCA;
	mov.u32 	%r208, 255;
	// begin inline asm
	call(%r175,%r176,%r177,%r178,%r179,%r180,%r181,%r182,%r183,%r184,%r185,%r186,%r187,%r188,%r189,%r190,%r191,%r192,%r193,%r194,%r195,%r196,%r197,%r198,%r199,%r200,%r201,%r202,%r203,%r204,%r205,%r206),_optix_trace_typed_32,(%r212,%rd18,%f1,%f2,%f3,%f187,%f188,%f4,%f192,%f191,%f192,%r208,%r213,%r212,%r213,%r212,%r213,%r833,%r250,%r251,%r252,%r253,%r254,%r255,%r256,%r257,%r258,%r259,%r260,%r261,%r262,%r263,%r264,%r265,%r266,%r267,%r268,%r269,%r270,%r271,%r272,%r273,%r274,%r275,%r276,%r277,%r278,%r279,%r280);
	// end inline asm
	setp.eq.s32 	%p18, %r175, -1;
	@%p18 bra 	$L__BB0_110;

	mul.wide.u32 	%rd134, %r175, 36;
	add.s64 	%rd135, %rd19, %rd134;
	ld.global.f32 	%f220, [%rd135];
	ld.global.f32 	%f221, [%rd135+12];
	sub.f32 	%f222, %f221, %f220;
	ld.global.f32 	%f223, [%rd135+4];
	ld.global.f32 	%f224, [%rd135+16];
	sub.f32 	%f225, %f224, %f223;
	ld.global.f32 	%f226, [%rd135+8];
	ld.global.f32 	%f227, [%rd135+20];
	sub.f32 	%f228, %f227, %f226;
	ld.global.f32 	%f229, [%rd135+24];
	sub.f32 	%f230, %f229, %f220;
	ld.global.f32 	%f231, [%rd135+28];
	sub.f32 	%f232, %f231, %f223;
	ld.global.f32 	%f233, [%rd135+32];
	sub.f32 	%f234, %f233, %f226;
	sub.f32 	%f235, %f1, %f220;
	sub.f32 	%f236, %f2, %f223;
	sub.f32 	%f237, %f3, %f226;
	mul.f32 	%f238, %f225, %f234;
	mul.f32 	%f239, %f228, %f232;
	sub.f32 	%f240, %f238, %f239;
	mul.f32 	%f241, %f228, %f230;
	mul.f32 	%f242, %f222, %f234;
	sub.f32 	%f243, %f241, %f242;
	mul.f32 	%f244, %f222, %f232;
	mul.f32 	%f245, %f225, %f230;
	sub.f32 	%f246, %f244, %f245;
	mul.f32 	%f247, %f4, %f236;
	mul.f32 	%f248, %f188, %f237;
	sub.f32 	%f249, %f247, %f248;
	mul.f32 	%f250, %f187, %f237;
	mul.f32 	%f251, %f4, %f235;
	sub.f32 	%f252, %f250, %f251;
	mul.f32 	%f253, %f188, %f235;
	mul.f32 	%f254, %f187, %f236;
	sub.f32 	%f255, %f253, %f254;
	mul.f32 	%f256, %f187, %f240;
	mul.f32 	%f257, %f188, %f243;
	mul.f32 	%f258, %f4, %f246;
	add.f32 	%f259, %f258, %f257;
	add.f32 	%f260, %f256, %f259;
	rcp.rn.f32 	%f261, %f260;
	mul.f32 	%f262, %f232, %f252;
	fma.rn.f32 	%f263, %f234, %f255, %f262;
	fma.rn.f32 	%f264, %f230, %f249, %f263;
	mul.f32 	%f265, %f261, %f264;
	mul.f32 	%f266, %f225, %f252;
	fma.rn.f32 	%f267, %f228, %f255, %f266;
	fma.rn.f32 	%f268, %f222, %f249, %f267;
	mul.f32 	%f269, %f261, %f268;
	mul.f32 	%f270, %f246, %f237;
	fma.rn.f32 	%f271, %f243, %f236, %f270;
	fma.rn.f32 	%f272, %f235, %f240, %f271;
	mul.f32 	%f13, %f272, %f261;
	setp.gt.f32 	%p19, %f265, 0f80000000;
	setp.lt.f32 	%p20, %f265, 0fBF800000;
	or.pred  	%p21, %p19, %p20;
	setp.lt.f32 	%p22, %f269, 0f00000000;
	or.pred  	%p23, %p22, %p21;
	sub.f32 	%f273, %f269, %f265;
	setp.gt.f32 	%p24, %f273, 0f3F800000;
	or.pred  	%p1, %p24, %p23;
	neg.f32 	%f274, %f258;
	sub.f32 	%f275, %f274, %f257;
	sub.f32 	%f276, %f275, %f256;
	mov.b32 	%r281, %f276;
	and.b32  	%r282, %r281, -2147483648;
	or.b32  	%r283, %r282, 1065353216;
	mov.b32 	%f277, %r283;
	mul.f32 	%f678, %f240, %f277;
	mul.f32 	%f677, %f243, %f277;
	mul.f32 	%f676, %f246, %f277;
	mul.f32 	%f278, %f676, %f676;
	fma.rn.f32 	%f279, %f677, %f677, %f278;
	fma.rn.f32 	%f17, %f678, %f678, %f279;
	setp.leu.f32 	%p25, %f17, 0f00000000;
	@%p25 bra 	$L__BB0_16;

	sqrt.rn.f32 	%f280, %f17;
	div.rn.f32 	%f678, %f678, %f280;
	div.rn.f32 	%f677, %f677, %f280;
	div.rn.f32 	%f676, %f676, %f280;

$L__BB0_16:
	mov.f32 	%f281, 0fBA83126F;
	sub.f32 	%f282, %f281, %f13;
	setp.gt.f32 	%p26, %f13, 0f80000000;
	or.pred  	%p27, %p26, %p1;
	selp.f32 	%f283, 0f7F7FFFFF, %f282, %p27;
	max.f32 	%f285, %f192, %f283;
	fma.rn.f32 	%f24, %f187, %f285, %f1;
	fma.rn.f32 	%f25, %f188, %f285, %f2;
	fma.rn.f32 	%f26, %f4, %f285, %f3;
	mul.lo.s64 	%rd136, %rd316, 6364136223846793005;
	add.s64 	%rd30, %rd136, -2720673578348880933;
	shr.u64 	%rd137, %rd316, 18;
	xor.b64  	%rd138, %rd137, %rd316;
	shr.u64 	%rd139, %rd138, 27;
	cvt.u32.u64 	%r284, %rd139;
	shr.u64 	%rd140, %rd316, 59;
	cvt.u32.u64 	%r285, %rd140;
	shf.r.wrap.b32 	%r286, %r284, %r284, %r285;
	shr.u32 	%r287, %r286, 9;
	or.b32  	%r288, %r287, 1065353216;
	mov.b32 	%f286, %r288;
	add.f32 	%f287, %f286, 0fBF800000;
	shr.u64 	%rd141, %rd30, 18;
	xor.b64  	%rd142, %rd141, %rd30;
	shr.u64 	%rd143, %rd142, 27;
	cvt.u32.u64 	%r289, %rd143;
	shr.u64 	%rd144, %rd30, 59;
	cvt.u32.u64 	%r290, %rd144;
	shf.r.wrap.b32 	%r291, %r289, %r289, %r290;
	shr.u32 	%r292, %r291, 9;
	or.b32  	%r293, %r292, 1065353216;
	mov.b32 	%f288, %r293;
	add.f32 	%f289, %f288, 0fBF800000;
	sqrt.rn.f32 	%f27, %f287;
	mul.f32 	%f28, %f289, 0f40C90FDB;
	mul.f32 	%f290, %f28, 0f3F22F983;
	cvt.rni.s32.f32 	%r843, %f290;
	cvt.rn.f32.s32 	%f291, %r843;
	fma.rn.f32 	%f293, %f291, %f176, %f28;
	fma.rn.f32 	%f295, %f291, %f178, %f293;
	fma.rn.f32 	%f682, %f291, %f180, %f295;
	abs.f32 	%f30, %f28;
	setp.leu.f32 	%p28, %f30, 0f47CE4780;
	mov.u32 	%r840, %r843;
	mov.f32 	%f679, %f682;
	@%p28 bra 	$L__BB0_24;

	setp.eq.f32 	%p29, %f30, 0f7F800000;
	@%p29 bra 	$L__BB0_23;
	bra.uni 	$L__BB0_18;

$L__BB0_23:
	mul.rn.f32 	%f679, %f28, %f192;
	mov.u32 	%r840, %r843;
	bra.uni 	$L__BB0_24;

$L__BB0_18:
	mov.b32 	%r24, %f28;
	bfe.u32 	%r294, %r24, 23, 8;
	add.s32 	%r25, %r294, -128;
	shl.b32 	%r295, %r24, 8;
	or.b32  	%r26, %r295, -2147483648;
	shr.u32 	%r27, %r25, 5;
	mov.u64 	%rd293, 0;
	mov.u64 	%rd292, %rd1;
	mov.u64 	%rd294, %rd293;

$L__BB0_19:
	.pragma "nounroll";
	shl.b64 	%rd147, %rd293, 2;
	mov.u64 	%rd148, __cudart_i2opi_f;
	add.s64 	%rd149, %rd148, %rd147;
	ld.global.nc.u32 	%r296, [%rd149];
	mad.wide.u32 	%rd150, %r296, %r26, %rd294;
	shr.u64 	%rd294, %rd150, 32;
	st.local.u32 	[%rd292], %rd150;
	cvt.u32.u64 	%r297, %rd293;
	add.s32 	%r298, %r297, 1;
	cvt.s64.s32 	%rd293, %r298;
	mul.wide.s32 	%rd151, %r298, 4;
	add.s64 	%rd292, %rd1, %rd151;
	setp.ne.s32 	%p30, %r298, 6;
	@%p30 bra 	$L__BB0_19;

	st.local.u32 	[%rd22], %rd294;
	mov.u32 	%r299, 4;
	sub.s32 	%r28, %r299, %r27;
	mov.u32 	%r300, 6;
	sub.s32 	%r301, %r300, %r27;
	mul.wide.s32 	%rd152, %r301, 4;
	add.s64 	%rd153, %rd1, %rd152;
	ld.local.u32 	%r838, [%rd153];
	ld.local.u32 	%r839, [%rd153+-4];
	and.b32  	%r31, %r25, 31;
	setp.eq.s32 	%p31, %r31, 0;
	@%p31 bra 	$L__BB0_22;

	mov.u32 	%r302, 32;
	sub.s32 	%r303, %r302, %r31;
	shr.u32 	%r304, %r839, %r303;
	shl.b32 	%r305, %r838, %r31;
	add.s32 	%r838, %r304, %r305;
	mul.wide.s32 	%rd154, %r28, 4;
	add.s64 	%rd155, %rd1, %rd154;
	ld.local.u32 	%r306, [%rd155];
	shr.u32 	%r307, %r306, %r303;
	shl.b32 	%r308, %r839, %r31;
	add.s32 	%r839, %r307, %r308;

$L__BB0_22:
	and.b32  	%r309, %r24, -2147483648;
	shr.u32 	%r310, %r839, 30;
	shl.b32 	%r311, %r838, 2;
	or.b32  	%r312, %r310, %r311;
	shr.u32 	%r313, %r312, 31;
	shr.u32 	%r314, %r838, 30;
	add.s32 	%r315, %r313, %r314;
	neg.s32 	%r316, %r315;
	setp.eq.s32 	%p32, %r309, 0;
	selp.b32 	%r840, %r315, %r316, %p32;
	setp.ne.s32 	%p33, %r313, 0;
	xor.b32  	%r317, %r309, -2147483648;
	selp.b32 	%r318, %r317, %r309, %p33;
	selp.b32 	%r319, -1, 0, %p33;
	xor.b32  	%r320, %r312, %r319;
	shl.b32 	%r321, %r839, 2;
	xor.b32  	%r322, %r321, %r319;
	cvt.u64.u32 	%rd156, %r320;
	cvt.u64.u32 	%rd157, %r322;
	bfi.b64 	%rd158, %rd156, %rd157, 32, 32;
	cvt.rn.f64.s64 	%fd3, %rd158;
	mul.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f297, %fd4;
	setp.eq.s32 	%p34, %r318, 0;
	neg.f32 	%f298, %f297;
	selp.f32 	%f679, %f297, %f298, %p34;

$L__BB0_24:
	mov.f32 	%f680, 0fB94D4153;
	add.s32 	%r38, %r840, 1;
	and.b32  	%r39, %r38, 1;
	setp.eq.s32 	%p35, %r39, 0;
	selp.f32 	%f34, %f679, 0f3F800000, %p35;
	mul.rn.f32 	%f35, %f679, %f679;
	@%p35 bra 	$L__BB0_26;

	mov.f32 	%f671, 0fBAB607ED;
	mov.f32 	%f670, 0f37CBAC00;
	fma.rn.f32 	%f680, %f670, %f35, %f671;

$L__BB0_26:
	selp.f32 	%f303, 0f3C0885E4, 0f3D2AAABB, %p35;
	fma.rn.f32 	%f304, %f680, %f35, %f303;
	selp.f32 	%f305, 0fBE2AAAA8, 0fBEFFFFFF, %p35;
	fma.rn.f32 	%f306, %f304, %f35, %f305;
	fma.rn.f32 	%f308, %f35, %f34, %f192;
	fma.rn.f32 	%f681, %f306, %f308, %f34;
	and.b32  	%r323, %r38, 2;
	setp.eq.s32 	%p37, %r323, 0;
	@%p37 bra 	$L__BB0_28;

	mov.f32 	%f310, 0fBF800000;
	fma.rn.f32 	%f681, %f681, %f310, %f192;

$L__BB0_28:
	@%p28 bra 	$L__BB0_36;

	setp.eq.f32 	%p39, %f30, 0f7F800000;
	@%p39 bra 	$L__BB0_35;
	bra.uni 	$L__BB0_30;

$L__BB0_35:
	mul.rn.f32 	%f682, %f28, %f192;
	bra.uni 	$L__BB0_36;

$L__BB0_30:
	mov.b32 	%r40, %f28;
	bfe.u32 	%r324, %r40, 23, 8;
	add.s32 	%r41, %r324, -128;
	shl.b32 	%r325, %r40, 8;
	or.b32  	%r42, %r325, -2147483648;
	shr.u32 	%r43, %r41, 5;
	mov.u64 	%rd296, 0;
	mov.u64 	%rd295, %rd1;
	mov.u64 	%rd297, %rd296;

$L__BB0_31:
	.pragma "nounroll";
	shl.b64 	%rd161, %rd296, 2;
	mov.u64 	%rd162, __cudart_i2opi_f;
	add.s64 	%rd163, %rd162, %rd161;
	ld.global.nc.u32 	%r326, [%rd163];
	mad.wide.u32 	%rd164, %r326, %r42, %rd297;
	shr.u64 	%rd297, %rd164, 32;
	st.local.u32 	[%rd295], %rd164;
	cvt.u32.u64 	%r327, %rd296;
	add.s32 	%r328, %r327, 1;
	cvt.s64.s32 	%rd296, %r328;
	mul.wide.s32 	%rd165, %r328, 4;
	add.s64 	%rd295, %rd1, %rd165;
	setp.ne.s32 	%p40, %r328, 6;
	@%p40 bra 	$L__BB0_31;

	st.local.u32 	[%rd22], %rd297;
	mov.u32 	%r329, 4;
	sub.s32 	%r44, %r329, %r43;
	mov.u32 	%r330, 6;
	sub.s32 	%r331, %r330, %r43;
	mul.wide.s32 	%rd166, %r331, 4;
	add.s64 	%rd167, %rd1, %rd166;
	ld.local.u32 	%r841, [%rd167];
	ld.local.u32 	%r842, [%rd167+-4];
	and.b32  	%r47, %r41, 31;
	setp.eq.s32 	%p41, %r47, 0;
	@%p41 bra 	$L__BB0_34;

	mov.u32 	%r332, 32;
	sub.s32 	%r333, %r332, %r47;
	shr.u32 	%r334, %r842, %r333;
	shl.b32 	%r335, %r841, %r47;
	add.s32 	%r841, %r334, %r335;
	mul.wide.s32 	%rd168, %r44, 4;
	add.s64 	%rd169, %rd1, %rd168;
	ld.local.u32 	%r336, [%rd169];
	shr.u32 	%r337, %r336, %r333;
	shl.b32 	%r338, %r842, %r47;
	add.s32 	%r842, %r337, %r338;

$L__BB0_34:
	and.b32  	%r339, %r40, -2147483648;
	shr.u32 	%r340, %r842, 30;
	shl.b32 	%r341, %r841, 2;
	or.b32  	%r342, %r340, %r341;
	shr.u32 	%r343, %r342, 31;
	shr.u32 	%r344, %r841, 30;
	add.s32 	%r345, %r343, %r344;
	neg.s32 	%r346, %r345;
	setp.eq.s32 	%p42, %r339, 0;
	selp.b32 	%r843, %r345, %r346, %p42;
	setp.ne.s32 	%p43, %r343, 0;
	xor.b32  	%r347, %r339, -2147483648;
	selp.b32 	%r348, %r347, %r339, %p43;
	selp.b32 	%r349, -1, 0, %p43;
	xor.b32  	%r350, %r342, %r349;
	shl.b32 	%r351, %r842, 2;
	xor.b32  	%r352, %r351, %r349;
	cvt.u64.u32 	%rd170, %r350;
	cvt.u64.u32 	%rd171, %r352;
	bfi.b64 	%rd172, %rd170, %rd171, 32, 32;
	cvt.rn.f64.s64 	%fd5, %rd172;
	mul.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f311, %fd6;
	setp.eq.s32 	%p44, %r348, 0;
	neg.f32 	%f312, %f311;
	selp.f32 	%f682, %f311, %f312, %p44;

$L__BB0_36:
	mul.f32 	%f44, %f27, %f681;
	and.b32  	%r54, %r843, 1;
	setp.eq.s32 	%p45, %r54, 0;
	selp.f32 	%f45, %f682, 0f3F800000, %p45;
	mul.rn.f32 	%f46, %f682, %f682;
	mov.f32 	%f683, 0fB94D4153;
	@%p45 bra 	$L__BB0_38;

	mov.f32 	%f673, 0fBAB607ED;
	mov.f32 	%f672, 0f37CBAC00;
	fma.rn.f32 	%f683, %f672, %f46, %f673;

$L__BB0_38:
	selp.f32 	%f317, 0f3C0885E4, 0f3D2AAABB, %p45;
	fma.rn.f32 	%f318, %f683, %f46, %f317;
	selp.f32 	%f319, 0fBE2AAAA8, 0fBEFFFFFF, %p45;
	fma.rn.f32 	%f320, %f318, %f46, %f319;
	fma.rn.f32 	%f322, %f46, %f45, %f192;
	fma.rn.f32 	%f684, %f320, %f322, %f45;
	and.b32  	%r353, %r843, 2;
	setp.eq.s32 	%p47, %r353, 0;
	@%p47 bra 	$L__BB0_40;

	mov.f32 	%f324, 0fBF800000;
	fma.rn.f32 	%f684, %f684, %f324, %f192;

$L__BB0_40:
	abs.f32 	%f325, %f676;
	abs.f32 	%f326, %f678;
	setp.gt.f32 	%p48, %f326, %f325;
	neg.f32 	%f327, %f676;
	selp.f32 	%f686, %f678, %f327, %p48;
	neg.f32 	%f328, %f677;
	selp.f32 	%f685, %f328, 0f00000000, %p48;
	selp.f32 	%f687, 0f00000000, %f677, %p48;
	mul.f32 	%f329, %f687, %f687;
	fma.rn.f32 	%f330, %f686, %f686, %f329;
	fma.rn.f32 	%f55, %f685, %f685, %f330;
	setp.leu.f32 	%p49, %f55, 0f00000000;
	@%p49 bra 	$L__BB0_42;

	sqrt.rn.f32 	%f331, %f55;
	div.rn.f32 	%f685, %f685, %f331;
	div.rn.f32 	%f686, %f686, %f331;
	div.rn.f32 	%f687, %f687, %f331;

$L__BB0_42:
	mov.u32 	%r830, 1;
	mov.u32 	%r829, 255;
	mov.f32 	%f674, 0f5A0E1BCA;
	mov.u32 	%r828, 0;
	mul.f32 	%f341, %f27, %f684;
	mul.f32 	%f342, %f341, %f341;
	mul.f32 	%f343, %f44, %f44;
	sub.f32 	%f345, %f172, %f343;
	sub.f32 	%f346, %f345, %f342;
	max.f32 	%f347, %f192, %f346;
	sqrt.rn.f32 	%f348, %f347;
	mul.f32 	%f349, %f677, %f687;
	mul.f32 	%f350, %f676, %f686;
	sub.f32 	%f351, %f350, %f349;
	mul.f32 	%f352, %f676, %f685;
	mul.f32 	%f353, %f678, %f687;
	sub.f32 	%f354, %f353, %f352;
	mul.f32 	%f355, %f678, %f686;
	mul.f32 	%f356, %f677, %f685;
	sub.f32 	%f357, %f356, %f355;
	mul.f32 	%f358, %f44, %f351;
	fma.rn.f32 	%f359, %f341, %f685, %f358;
	fma.rn.f32 	%f62, %f678, %f348, %f359;
	mul.f32 	%f360, %f44, %f354;
	fma.rn.f32 	%f361, %f341, %f686, %f360;
	fma.rn.f32 	%f63, %f677, %f348, %f361;
	mul.f32 	%f362, %f44, %f357;
	fma.rn.f32 	%f363, %f341, %f687, %f362;
	fma.rn.f32 	%f64, %f676, %f348, %f363;
	mul.lo.s64 	%rd174, %rd30, 6364136223846793005;
	add.s64 	%rd316, %rd174, -2720673578348880933;
	// begin inline asm
	call(%r354,%r355,%r356,%r357,%r358,%r359,%r360,%r361,%r362,%r363,%r364,%r365,%r366,%r367,%r368,%r369,%r370,%r371,%r372,%r373,%r374,%r375,%r376,%r377,%r378,%r379,%r380,%r381,%r382,%r383,%r384,%r385),_optix_trace_typed_32,(%r828,%rd18,%f24,%f25,%f26,%f62,%f63,%f64,%f192,%f674,%f192,%r829,%r830,%r828,%r830,%r828,%r830,%r175,%r425,%r426,%r427,%r428,%r429,%r430,%r431,%r432,%r433,%r434,%r435,%r436,%r437,%r438,%r439,%r440,%r441,%r442,%r443,%r444,%r445,%r446,%r447,%r448,%r449,%r450,%r451,%r452,%r453,%r454,%r455);
	// end inline asm
	setp.eq.s32 	%p50, %r354, -1;
	@%p50 bra 	$L__BB0_110;

	mul.wide.u32 	%rd175, %r354, 36;
	add.s64 	%rd176, %rd19, %rd175;
	ld.global.f32 	%f364, [%rd176];
	ld.global.f32 	%f365, [%rd176+12];
	sub.f32 	%f366, %f365, %f364;
	ld.global.f32 	%f367, [%rd176+4];
	ld.global.f32 	%f368, [%rd176+16];
	sub.f32 	%f369, %f368, %f367;
	ld.global.f32 	%f370, [%rd176+8];
	ld.global.f32 	%f371, [%rd176+20];
	sub.f32 	%f372, %f371, %f370;
	ld.global.f32 	%f373, [%rd176+24];
	sub.f32 	%f374, %f373, %f364;
	ld.global.f32 	%f375, [%rd176+28];
	sub.f32 	%f376, %f375, %f367;
	ld.global.f32 	%f377, [%rd176+32];
	sub.f32 	%f378, %f377, %f370;
	sub.f32 	%f379, %f24, %f364;
	sub.f32 	%f380, %f25, %f367;
	sub.f32 	%f381, %f26, %f370;
	mul.f32 	%f382, %f369, %f378;
	mul.f32 	%f383, %f372, %f376;
	sub.f32 	%f384, %f382, %f383;
	mul.f32 	%f385, %f372, %f374;
	mul.f32 	%f386, %f366, %f378;
	sub.f32 	%f387, %f385, %f386;
	mul.f32 	%f388, %f366, %f376;
	mul.f32 	%f389, %f369, %f374;
	sub.f32 	%f390, %f388, %f389;
	mul.f32 	%f391, %f64, %f380;
	mul.f32 	%f392, %f63, %f381;
	sub.f32 	%f393, %f391, %f392;
	mul.f32 	%f394, %f62, %f381;
	mul.f32 	%f395, %f64, %f379;
	sub.f32 	%f396, %f394, %f395;
	mul.f32 	%f397, %f63, %f379;
	mul.f32 	%f398, %f62, %f380;
	sub.f32 	%f399, %f397, %f398;
	mul.f32 	%f400, %f62, %f384;
	mul.f32 	%f401, %f63, %f387;
	mul.f32 	%f402, %f64, %f390;
	add.f32 	%f403, %f402, %f401;
	add.f32 	%f404, %f400, %f403;
	rcp.rn.f32 	%f405, %f404;
	mul.f32 	%f406, %f376, %f396;
	fma.rn.f32 	%f407, %f378, %f399, %f406;
	fma.rn.f32 	%f408, %f374, %f393, %f407;
	mul.f32 	%f409, %f405, %f408;
	mul.f32 	%f410, %f369, %f396;
	fma.rn.f32 	%f411, %f372, %f399, %f410;
	fma.rn.f32 	%f412, %f366, %f393, %f411;
	mul.f32 	%f413, %f405, %f412;
	mul.f32 	%f414, %f390, %f381;
	fma.rn.f32 	%f415, %f387, %f380, %f414;
	fma.rn.f32 	%f416, %f379, %f384, %f415;
	mul.f32 	%f65, %f416, %f405;
	setp.gt.f32 	%p51, %f409, 0f80000000;
	setp.lt.f32 	%p52, %f409, 0fBF800000;
	or.pred  	%p53, %p51, %p52;
	setp.lt.f32 	%p54, %f413, 0f00000000;
	or.pred  	%p55, %p54, %p53;
	sub.f32 	%f417, %f413, %f409;
	setp.gt.f32 	%p56, %f417, 0f3F800000;
	or.pred  	%p2, %p56, %p55;
	neg.f32 	%f418, %f402;
	sub.f32 	%f419, %f418, %f401;
	sub.f32 	%f420, %f419, %f400;
	mov.b32 	%r456, %f420;
	and.b32  	%r457, %r456, -2147483648;
	or.b32  	%r458, %r457, 1065353216;
	mov.b32 	%f421, %r458;
	mul.f32 	%f690, %f384, %f421;
	mul.f32 	%f689, %f387, %f421;
	mul.f32 	%f688, %f390, %f421;
	mul.f32 	%f422, %f688, %f688;
	fma.rn.f32 	%f423, %f689, %f689, %f422;
	fma.rn.f32 	%f69, %f690, %f690, %f423;
	setp.leu.f32 	%p57, %f69, 0f00000000;
	@%p57 bra 	$L__BB0_45;

	sqrt.rn.f32 	%f424, %f69;
	div.rn.f32 	%f690, %f690, %f424;
	div.rn.f32 	%f689, %f689, %f424;
	div.rn.f32 	%f688, %f688, %f424;

$L__BB0_45:
	mov.f32 	%f657, 0fBA83126F;
	sub.f32 	%f426, %f657, %f65;
	setp.gt.f32 	%p58, %f65, 0f80000000;
	or.pred  	%p59, %p58, %p2;
	selp.f32 	%f427, 0f7F7FFFFF, %f426, %p59;
	max.f32 	%f429, %f192, %f427;
	fma.rn.f32 	%f76, %f62, %f429, %f24;
	fma.rn.f32 	%f77, %f63, %f429, %f25;
	fma.rn.f32 	%f78, %f64, %f429, %f26;
	mul.lo.s64 	%rd177, %rd316, 6364136223846793005;
	add.s64 	%rd46, %rd177, -2720673578348880933;
	shr.u64 	%rd178, %rd316, 18;
	xor.b64  	%rd179, %rd178, %rd316;
	shr.u64 	%rd180, %rd179, 27;
	cvt.u32.u64 	%r459, %rd180;
	shr.u64 	%rd181, %rd316, 59;
	cvt.u32.u64 	%r460, %rd181;
	shf.r.wrap.b32 	%r461, %r459, %r459, %r460;
	shr.u32 	%r462, %r461, 9;
	or.b32  	%r463, %r462, 1065353216;
	mov.b32 	%f430, %r463;
	add.f32 	%f431, %f430, 0fBF800000;
	shr.u64 	%rd182, %rd46, 18;
	xor.b64  	%rd183, %rd182, %rd46;
	shr.u64 	%rd184, %rd183, 27;
	cvt.u32.u64 	%r464, %rd184;
	shr.u64 	%rd185, %rd46, 59;
	cvt.u32.u64 	%r465, %rd185;
	shf.r.wrap.b32 	%r466, %r464, %r464, %r465;
	shr.u32 	%r467, %r466, 9;
	or.b32  	%r468, %r467, 1065353216;
	mov.b32 	%f432, %r468;
	add.f32 	%f433, %f432, 0fBF800000;
	sqrt.rn.f32 	%f79, %f431;
	mul.f32 	%f80, %f433, 0f40C90FDB;
	mul.f32 	%f434, %f80, 0f3F22F983;
	cvt.rni.s32.f32 	%r849, %f434;
	cvt.rn.f32.s32 	%f435, %r849;
	fma.rn.f32 	%f437, %f435, %f176, %f80;
	fma.rn.f32 	%f439, %f435, %f178, %f437;
	fma.rn.f32 	%f694, %f435, %f180, %f439;
	abs.f32 	%f82, %f80;
	setp.leu.f32 	%p60, %f82, 0f47CE4780;
	mov.u32 	%r846, %r849;
	mov.f32 	%f691, %f694;
	@%p60 bra 	$L__BB0_53;

	setp.eq.f32 	%p61, %f82, 0f7F800000;
	@%p61 bra 	$L__BB0_52;
	bra.uni 	$L__BB0_47;

$L__BB0_52:
	mul.rn.f32 	%f691, %f80, %f192;
	mov.u32 	%r846, %r849;
	bra.uni 	$L__BB0_53;

$L__BB0_47:
	mov.b32 	%r57, %f80;
	bfe.u32 	%r469, %r57, 23, 8;
	add.s32 	%r58, %r469, -128;
	shl.b32 	%r470, %r57, 8;
	or.b32  	%r59, %r470, -2147483648;
	shr.u32 	%r60, %r58, 5;
	mov.u64 	%rd299, 0;
	mov.u64 	%rd298, %rd1;
	mov.u64 	%rd300, %rd299;

$L__BB0_48:
	.pragma "nounroll";
	shl.b64 	%rd188, %rd299, 2;
	mov.u64 	%rd189, __cudart_i2opi_f;
	add.s64 	%rd190, %rd189, %rd188;
	ld.global.nc.u32 	%r471, [%rd190];
	mad.wide.u32 	%rd191, %r471, %r59, %rd300;
	shr.u64 	%rd300, %rd191, 32;
	st.local.u32 	[%rd298], %rd191;
	cvt.u32.u64 	%r472, %rd299;
	add.s32 	%r473, %r472, 1;
	cvt.s64.s32 	%rd299, %r473;
	mul.wide.s32 	%rd192, %r473, 4;
	add.s64 	%rd298, %rd1, %rd192;
	setp.ne.s32 	%p62, %r473, 6;
	@%p62 bra 	$L__BB0_48;

	st.local.u32 	[%rd22], %rd300;
	mov.u32 	%r474, 4;
	sub.s32 	%r61, %r474, %r60;
	mov.u32 	%r475, 6;
	sub.s32 	%r476, %r475, %r60;
	mul.wide.s32 	%rd193, %r476, 4;
	add.s64 	%rd194, %rd1, %rd193;
	ld.local.u32 	%r844, [%rd194];
	ld.local.u32 	%r845, [%rd194+-4];
	and.b32  	%r64, %r58, 31;
	setp.eq.s32 	%p63, %r64, 0;
	@%p63 bra 	$L__BB0_51;

	mov.u32 	%r477, 32;
	sub.s32 	%r478, %r477, %r64;
	shr.u32 	%r479, %r845, %r478;
	shl.b32 	%r480, %r844, %r64;
	add.s32 	%r844, %r479, %r480;
	mul.wide.s32 	%rd195, %r61, 4;
	add.s64 	%rd196, %rd1, %rd195;
	ld.local.u32 	%r481, [%rd196];
	shr.u32 	%r482, %r481, %r478;
	shl.b32 	%r483, %r845, %r64;
	add.s32 	%r845, %r482, %r483;

$L__BB0_51:
	and.b32  	%r484, %r57, -2147483648;
	shr.u32 	%r485, %r845, 30;
	shl.b32 	%r486, %r844, 2;
	or.b32  	%r487, %r485, %r486;
	shr.u32 	%r488, %r487, 31;
	shr.u32 	%r489, %r844, 30;
	add.s32 	%r490, %r488, %r489;
	neg.s32 	%r491, %r490;
	setp.eq.s32 	%p64, %r484, 0;
	selp.b32 	%r846, %r490, %r491, %p64;
	setp.ne.s32 	%p65, %r488, 0;
	xor.b32  	%r492, %r484, -2147483648;
	selp.b32 	%r493, %r492, %r484, %p65;
	selp.b32 	%r494, -1, 0, %p65;
	xor.b32  	%r495, %r487, %r494;
	shl.b32 	%r496, %r845, 2;
	xor.b32  	%r497, %r496, %r494;
	cvt.u64.u32 	%rd197, %r495;
	cvt.u64.u32 	%rd198, %r497;
	bfi.b64 	%rd199, %rd197, %rd198, 32, 32;
	cvt.rn.f64.s64 	%fd7, %rd199;
	mul.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f441, %fd8;
	setp.eq.s32 	%p66, %r493, 0;
	neg.f32 	%f442, %f441;
	selp.f32 	%f691, %f441, %f442, %p66;

$L__BB0_53:
	add.s32 	%r71, %r846, 1;
	and.b32  	%r72, %r71, 1;
	setp.eq.s32 	%p67, %r72, 0;
	selp.f32 	%f86, %f691, 0f3F800000, %p67;
	mul.rn.f32 	%f87, %f691, %f691;
	mov.f32 	%f692, 0fB94D4153;
	@%p67 bra 	$L__BB0_55;

	mov.f32 	%f659, 0fBAB607ED;
	mov.f32 	%f658, 0f37CBAC00;
	fma.rn.f32 	%f692, %f658, %f87, %f659;

$L__BB0_55:
	selp.f32 	%f447, 0f3C0885E4, 0f3D2AAABB, %p67;
	fma.rn.f32 	%f448, %f692, %f87, %f447;
	selp.f32 	%f449, 0fBE2AAAA8, 0fBEFFFFFF, %p67;
	fma.rn.f32 	%f450, %f448, %f87, %f449;
	fma.rn.f32 	%f452, %f87, %f86, %f192;
	fma.rn.f32 	%f693, %f450, %f452, %f86;
	and.b32  	%r498, %r71, 2;
	setp.eq.s32 	%p69, %r498, 0;
	@%p69 bra 	$L__BB0_57;

	mov.f32 	%f454, 0fBF800000;
	fma.rn.f32 	%f693, %f693, %f454, %f192;

$L__BB0_57:
	@%p60 bra 	$L__BB0_65;

	setp.eq.f32 	%p71, %f82, 0f7F800000;
	@%p71 bra 	$L__BB0_64;
	bra.uni 	$L__BB0_59;

$L__BB0_64:
	mul.rn.f32 	%f694, %f80, %f192;
	bra.uni 	$L__BB0_65;

$L__BB0_59:
	mov.b32 	%r73, %f80;
	bfe.u32 	%r499, %r73, 23, 8;
	add.s32 	%r74, %r499, -128;
	shl.b32 	%r500, %r73, 8;
	or.b32  	%r75, %r500, -2147483648;
	shr.u32 	%r76, %r74, 5;
	mov.u64 	%rd302, 0;
	mov.u64 	%rd301, %rd1;
	mov.u64 	%rd303, %rd302;

$L__BB0_60:
	.pragma "nounroll";
	shl.b64 	%rd202, %rd302, 2;
	mov.u64 	%rd203, __cudart_i2opi_f;
	add.s64 	%rd204, %rd203, %rd202;
	ld.global.nc.u32 	%r501, [%rd204];
	mad.wide.u32 	%rd205, %r501, %r75, %rd303;
	shr.u64 	%rd303, %rd205, 32;
	st.local.u32 	[%rd301], %rd205;
	cvt.u32.u64 	%r502, %rd302;
	add.s32 	%r503, %r502, 1;
	cvt.s64.s32 	%rd302, %r503;
	mul.wide.s32 	%rd206, %r503, 4;
	add.s64 	%rd301, %rd1, %rd206;
	setp.ne.s32 	%p72, %r503, 6;
	@%p72 bra 	$L__BB0_60;

	st.local.u32 	[%rd22], %rd303;
	mov.u32 	%r504, 4;
	sub.s32 	%r77, %r504, %r76;
	mov.u32 	%r505, 6;
	sub.s32 	%r506, %r505, %r76;
	mul.wide.s32 	%rd207, %r506, 4;
	add.s64 	%rd208, %rd1, %rd207;
	ld.local.u32 	%r847, [%rd208];
	ld.local.u32 	%r848, [%rd208+-4];
	and.b32  	%r80, %r74, 31;
	setp.eq.s32 	%p73, %r80, 0;
	@%p73 bra 	$L__BB0_63;

	mov.u32 	%r507, 32;
	sub.s32 	%r508, %r507, %r80;
	shr.u32 	%r509, %r848, %r508;
	shl.b32 	%r510, %r847, %r80;
	add.s32 	%r847, %r509, %r510;
	mul.wide.s32 	%rd209, %r77, 4;
	add.s64 	%rd210, %rd1, %rd209;
	ld.local.u32 	%r511, [%rd210];
	shr.u32 	%r512, %r511, %r508;
	shl.b32 	%r513, %r848, %r80;
	add.s32 	%r848, %r512, %r513;

$L__BB0_63:
	and.b32  	%r514, %r73, -2147483648;
	shr.u32 	%r515, %r848, 30;
	shl.b32 	%r516, %r847, 2;
	or.b32  	%r517, %r515, %r516;
	shr.u32 	%r518, %r517, 31;
	shr.u32 	%r519, %r847, 30;
	add.s32 	%r520, %r518, %r519;
	neg.s32 	%r521, %r520;
	setp.eq.s32 	%p74, %r514, 0;
	selp.b32 	%r849, %r520, %r521, %p74;
	setp.ne.s32 	%p75, %r518, 0;
	xor.b32  	%r522, %r514, -2147483648;
	selp.b32 	%r523, %r522, %r514, %p75;
	selp.b32 	%r524, -1, 0, %p75;
	xor.b32  	%r525, %r517, %r524;
	shl.b32 	%r526, %r848, 2;
	xor.b32  	%r527, %r526, %r524;
	cvt.u64.u32 	%rd211, %r525;
	cvt.u64.u32 	%rd212, %r527;
	bfi.b64 	%rd213, %rd211, %rd212, 32, 32;
	cvt.rn.f64.s64 	%fd9, %rd213;
	mul.f64 	%fd10, %fd9, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f455, %fd10;
	setp.eq.s32 	%p76, %r523, 0;
	neg.f32 	%f456, %f455;
	selp.f32 	%f694, %f455, %f456, %p76;

$L__BB0_65:
	mul.f32 	%f96, %f79, %f693;
	and.b32  	%r87, %r849, 1;
	setp.eq.s32 	%p77, %r87, 0;
	selp.f32 	%f97, %f694, 0f3F800000, %p77;
	mul.rn.f32 	%f98, %f694, %f694;
	mov.f32 	%f695, 0fB94D4153;
	@%p77 bra 	$L__BB0_67;

	mov.f32 	%f661, 0fBAB607ED;
	mov.f32 	%f660, 0f37CBAC00;
	fma.rn.f32 	%f695, %f660, %f98, %f661;

$L__BB0_67:
	selp.f32 	%f461, 0f3C0885E4, 0f3D2AAABB, %p77;
	fma.rn.f32 	%f462, %f695, %f98, %f461;
	selp.f32 	%f463, 0fBE2AAAA8, 0fBEFFFFFF, %p77;
	fma.rn.f32 	%f464, %f462, %f98, %f463;
	fma.rn.f32 	%f466, %f98, %f97, %f192;
	fma.rn.f32 	%f696, %f464, %f466, %f97;
	and.b32  	%r528, %r849, 2;
	setp.eq.s32 	%p79, %r528, 0;
	@%p79 bra 	$L__BB0_69;

	mov.f32 	%f468, 0fBF800000;
	fma.rn.f32 	%f696, %f696, %f468, %f192;

$L__BB0_69:
	abs.f32 	%f469, %f688;
	abs.f32 	%f470, %f690;
	setp.gt.f32 	%p80, %f470, %f469;
	neg.f32 	%f471, %f688;
	selp.f32 	%f698, %f690, %f471, %p80;
	neg.f32 	%f472, %f689;
	selp.f32 	%f697, %f472, 0f00000000, %p80;
	selp.f32 	%f699, 0f00000000, %f689, %p80;
	mul.f32 	%f473, %f699, %f699;
	fma.rn.f32 	%f474, %f698, %f698, %f473;
	fma.rn.f32 	%f107, %f697, %f697, %f474;
	setp.leu.f32 	%p81, %f107, 0f00000000;
	@%p81 bra 	$L__BB0_71;

	sqrt.rn.f32 	%f475, %f107;
	div.rn.f32 	%f697, %f697, %f475;
	div.rn.f32 	%f698, %f698, %f475;
	div.rn.f32 	%f699, %f699, %f475;

$L__BB0_71:
	mov.u32 	%r824, 1;
	mov.u32 	%r823, 255;
	mov.f32 	%f662, 0f5A0E1BCA;
	mov.u32 	%r822, 0;
	mul.f32 	%f485, %f79, %f696;
	mul.f32 	%f486, %f485, %f485;
	mul.f32 	%f487, %f96, %f96;
	sub.f32 	%f489, %f172, %f487;
	sub.f32 	%f490, %f489, %f486;
	max.f32 	%f491, %f192, %f490;
	sqrt.rn.f32 	%f492, %f491;
	mul.f32 	%f493, %f689, %f699;
	mul.f32 	%f494, %f688, %f698;
	sub.f32 	%f495, %f494, %f493;
	mul.f32 	%f496, %f688, %f697;
	mul.f32 	%f497, %f690, %f699;
	sub.f32 	%f498, %f497, %f496;
	mul.f32 	%f499, %f690, %f698;
	mul.f32 	%f500, %f689, %f697;
	sub.f32 	%f501, %f500, %f499;
	mul.f32 	%f502, %f96, %f495;
	fma.rn.f32 	%f503, %f485, %f697, %f502;
	fma.rn.f32 	%f114, %f690, %f492, %f503;
	mul.f32 	%f504, %f96, %f498;
	fma.rn.f32 	%f505, %f485, %f698, %f504;
	fma.rn.f32 	%f115, %f689, %f492, %f505;
	mul.f32 	%f506, %f96, %f501;
	fma.rn.f32 	%f507, %f485, %f699, %f506;
	fma.rn.f32 	%f116, %f688, %f492, %f507;
	mul.lo.s64 	%rd215, %rd46, 6364136223846793005;
	add.s64 	%rd316, %rd215, -2720673578348880933;
	// begin inline asm
	call(%r529,%r530,%r531,%r532,%r533,%r534,%r535,%r536,%r537,%r538,%r539,%r540,%r541,%r542,%r543,%r544,%r545,%r546,%r547,%r548,%r549,%r550,%r551,%r552,%r553,%r554,%r555,%r556,%r557,%r558,%r559,%r560),_optix_trace_typed_32,(%r822,%rd18,%f76,%f77,%f78,%f114,%f115,%f116,%f192,%f662,%f192,%r823,%r824,%r822,%r824,%r822,%r824,%r354,%r600,%r601,%r602,%r603,%r604,%r605,%r606,%r607,%r608,%r609,%r610,%r611,%r612,%r613,%r614,%r615,%r616,%r617,%r618,%r619,%r620,%r621,%r622,%r623,%r624,%r625,%r626,%r627,%r628,%r629,%r630);
	// end inline asm
	setp.eq.s32 	%p82, %r529, -1;
	@%p82 bra 	$L__BB0_110;

	mul.wide.u32 	%rd216, %r529, 36;
	add.s64 	%rd217, %rd19, %rd216;
	ld.global.f32 	%f508, [%rd217];
	ld.global.f32 	%f509, [%rd217+12];
	sub.f32 	%f510, %f509, %f508;
	ld.global.f32 	%f511, [%rd217+4];
	ld.global.f32 	%f512, [%rd217+16];
	sub.f32 	%f513, %f512, %f511;
	ld.global.f32 	%f514, [%rd217+8];
	ld.global.f32 	%f515, [%rd217+20];
	sub.f32 	%f516, %f515, %f514;
	ld.global.f32 	%f517, [%rd217+24];
	sub.f32 	%f518, %f517, %f508;
	ld.global.f32 	%f519, [%rd217+28];
	sub.f32 	%f520, %f519, %f511;
	ld.global.f32 	%f521, [%rd217+32];
	sub.f32 	%f522, %f521, %f514;
	sub.f32 	%f523, %f76, %f508;
	sub.f32 	%f524, %f77, %f511;
	sub.f32 	%f525, %f78, %f514;
	mul.f32 	%f526, %f513, %f522;
	mul.f32 	%f527, %f516, %f520;
	sub.f32 	%f528, %f526, %f527;
	mul.f32 	%f529, %f516, %f518;
	mul.f32 	%f530, %f510, %f522;
	sub.f32 	%f531, %f529, %f530;
	mul.f32 	%f532, %f510, %f520;
	mul.f32 	%f533, %f513, %f518;
	sub.f32 	%f534, %f532, %f533;
	mul.f32 	%f535, %f116, %f524;
	mul.f32 	%f536, %f115, %f525;
	sub.f32 	%f537, %f535, %f536;
	mul.f32 	%f538, %f114, %f525;
	mul.f32 	%f539, %f116, %f523;
	sub.f32 	%f540, %f538, %f539;
	mul.f32 	%f541, %f115, %f523;
	mul.f32 	%f542, %f114, %f524;
	sub.f32 	%f543, %f541, %f542;
	mul.f32 	%f544, %f114, %f528;
	mul.f32 	%f545, %f115, %f531;
	mul.f32 	%f546, %f116, %f534;
	add.f32 	%f547, %f546, %f545;
	add.f32 	%f548, %f544, %f547;
	rcp.rn.f32 	%f549, %f548;
	mul.f32 	%f550, %f520, %f540;
	fma.rn.f32 	%f551, %f522, %f543, %f550;
	fma.rn.f32 	%f552, %f518, %f537, %f551;
	mul.f32 	%f553, %f549, %f552;
	mul.f32 	%f554, %f513, %f540;
	fma.rn.f32 	%f555, %f516, %f543, %f554;
	fma.rn.f32 	%f556, %f510, %f537, %f555;
	mul.f32 	%f557, %f549, %f556;
	mul.f32 	%f558, %f534, %f525;
	fma.rn.f32 	%f559, %f531, %f524, %f558;
	fma.rn.f32 	%f560, %f523, %f528, %f559;
	mul.f32 	%f117, %f560, %f549;
	setp.gt.f32 	%p83, %f553, 0f80000000;
	setp.lt.f32 	%p84, %f553, 0fBF800000;
	or.pred  	%p85, %p83, %p84;
	setp.lt.f32 	%p86, %f557, 0f00000000;
	or.pred  	%p87, %p86, %p85;
	sub.f32 	%f561, %f557, %f553;
	setp.gt.f32 	%p88, %f561, 0f3F800000;
	or.pred  	%p3, %p88, %p87;
	neg.f32 	%f562, %f546;
	sub.f32 	%f563, %f562, %f545;
	sub.f32 	%f564, %f563, %f544;
	mov.b32 	%r631, %f564;
	and.b32  	%r632, %r631, -2147483648;
	or.b32  	%r633, %r632, 1065353216;
	mov.b32 	%f565, %r633;
	mul.f32 	%f702, %f528, %f565;
	mul.f32 	%f701, %f531, %f565;
	mul.f32 	%f700, %f534, %f565;
	mul.f32 	%f566, %f700, %f700;
	fma.rn.f32 	%f567, %f701, %f701, %f566;
	fma.rn.f32 	%f121, %f702, %f702, %f567;
	setp.leu.f32 	%p89, %f121, 0f00000000;
	@%p89 bra 	$L__BB0_74;

	sqrt.rn.f32 	%f568, %f121;
	div.rn.f32 	%f702, %f702, %f568;
	div.rn.f32 	%f701, %f701, %f568;
	div.rn.f32 	%f700, %f700, %f568;

$L__BB0_74:
	mov.f32 	%f663, 0fBA83126F;
	sub.f32 	%f570, %f663, %f117;
	setp.gt.f32 	%p90, %f117, 0f80000000;
	or.pred  	%p91, %p90, %p3;
	selp.f32 	%f571, 0f7F7FFFFF, %f570, %p91;
	max.f32 	%f573, %f192, %f571;
	fma.rn.f32 	%f128, %f114, %f573, %f76;
	fma.rn.f32 	%f129, %f115, %f573, %f77;
	fma.rn.f32 	%f130, %f116, %f573, %f78;
	mul.lo.s64 	%rd218, %rd316, 6364136223846793005;
	add.s64 	%rd62, %rd218, -2720673578348880933;
	shr.u64 	%rd219, %rd316, 18;
	xor.b64  	%rd220, %rd219, %rd316;
	shr.u64 	%rd221, %rd220, 27;
	cvt.u32.u64 	%r634, %rd221;
	shr.u64 	%rd222, %rd316, 59;
	cvt.u32.u64 	%r635, %rd222;
	shf.r.wrap.b32 	%r636, %r634, %r634, %r635;
	shr.u32 	%r637, %r636, 9;
	or.b32  	%r638, %r637, 1065353216;
	mov.b32 	%f574, %r638;
	add.f32 	%f575, %f574, 0fBF800000;
	shr.u64 	%rd223, %rd62, 18;
	xor.b64  	%rd224, %rd223, %rd62;
	shr.u64 	%rd225, %rd224, 27;
	cvt.u32.u64 	%r639, %rd225;
	shr.u64 	%rd226, %rd62, 59;
	cvt.u32.u64 	%r640, %rd226;
	shf.r.wrap.b32 	%r641, %r639, %r639, %r640;
	shr.u32 	%r642, %r641, 9;
	or.b32  	%r643, %r642, 1065353216;
	mov.b32 	%f576, %r643;
	add.f32 	%f577, %f576, 0fBF800000;
	sqrt.rn.f32 	%f131, %f575;
	mul.f32 	%f132, %f577, 0f40C90FDB;
	mul.f32 	%f578, %f132, 0f3F22F983;
	cvt.rni.s32.f32 	%r855, %f578;
	cvt.rn.f32.s32 	%f579, %r855;
	fma.rn.f32 	%f581, %f579, %f176, %f132;
	fma.rn.f32 	%f583, %f579, %f178, %f581;
	fma.rn.f32 	%f706, %f579, %f180, %f583;
	abs.f32 	%f134, %f132;
	setp.leu.f32 	%p92, %f134, 0f47CE4780;
	mov.u32 	%r852, %r855;
	mov.f32 	%f703, %f706;
	@%p92 bra 	$L__BB0_82;

	setp.eq.f32 	%p93, %f134, 0f7F800000;
	@%p93 bra 	$L__BB0_81;
	bra.uni 	$L__BB0_76;

$L__BB0_81:
	mul.rn.f32 	%f703, %f132, %f192;
	mov.u32 	%r852, %r855;
	bra.uni 	$L__BB0_82;

$L__BB0_76:
	mov.b32 	%r90, %f132;
	bfe.u32 	%r644, %r90, 23, 8;
	add.s32 	%r91, %r644, -128;
	shl.b32 	%r645, %r90, 8;
	or.b32  	%r92, %r645, -2147483648;
	shr.u32 	%r93, %r91, 5;
	mov.u64 	%rd305, 0;
	mov.u64 	%rd304, %rd1;
	mov.u64 	%rd306, %rd305;

$L__BB0_77:
	.pragma "nounroll";
	shl.b64 	%rd229, %rd305, 2;
	mov.u64 	%rd230, __cudart_i2opi_f;
	add.s64 	%rd231, %rd230, %rd229;
	ld.global.nc.u32 	%r646, [%rd231];
	mad.wide.u32 	%rd232, %r646, %r92, %rd306;
	shr.u64 	%rd306, %rd232, 32;
	st.local.u32 	[%rd304], %rd232;
	cvt.u32.u64 	%r647, %rd305;
	add.s32 	%r648, %r647, 1;
	cvt.s64.s32 	%rd305, %r648;
	mul.wide.s32 	%rd233, %r648, 4;
	add.s64 	%rd304, %rd1, %rd233;
	setp.ne.s32 	%p94, %r648, 6;
	@%p94 bra 	$L__BB0_77;

	st.local.u32 	[%rd22], %rd306;
	mov.u32 	%r649, 4;
	sub.s32 	%r94, %r649, %r93;
	mov.u32 	%r650, 6;
	sub.s32 	%r651, %r650, %r93;
	mul.wide.s32 	%rd234, %r651, 4;
	add.s64 	%rd235, %rd1, %rd234;
	ld.local.u32 	%r850, [%rd235];
	ld.local.u32 	%r851, [%rd235+-4];
	and.b32  	%r97, %r91, 31;
	setp.eq.s32 	%p95, %r97, 0;
	@%p95 bra 	$L__BB0_80;

	mov.u32 	%r652, 32;
	sub.s32 	%r653, %r652, %r97;
	shr.u32 	%r654, %r851, %r653;
	shl.b32 	%r655, %r850, %r97;
	add.s32 	%r850, %r654, %r655;
	mul.wide.s32 	%rd236, %r94, 4;
	add.s64 	%rd237, %rd1, %rd236;
	ld.local.u32 	%r656, [%rd237];
	shr.u32 	%r657, %r656, %r653;
	shl.b32 	%r658, %r851, %r97;
	add.s32 	%r851, %r657, %r658;

$L__BB0_80:
	and.b32  	%r659, %r90, -2147483648;
	shr.u32 	%r660, %r851, 30;
	shl.b32 	%r661, %r850, 2;
	or.b32  	%r662, %r660, %r661;
	shr.u32 	%r663, %r662, 31;
	shr.u32 	%r664, %r850, 30;
	add.s32 	%r665, %r663, %r664;
	neg.s32 	%r666, %r665;
	setp.eq.s32 	%p96, %r659, 0;
	selp.b32 	%r852, %r665, %r666, %p96;
	setp.ne.s32 	%p97, %r663, 0;
	xor.b32  	%r667, %r659, -2147483648;
	selp.b32 	%r668, %r667, %r659, %p97;
	selp.b32 	%r669, -1, 0, %p97;
	xor.b32  	%r670, %r662, %r669;
	shl.b32 	%r671, %r851, 2;
	xor.b32  	%r672, %r671, %r669;
	cvt.u64.u32 	%rd238, %r670;
	cvt.u64.u32 	%rd239, %r672;
	bfi.b64 	%rd240, %rd238, %rd239, 32, 32;
	cvt.rn.f64.s64 	%fd11, %rd240;
	mul.f64 	%fd12, %fd11, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f585, %fd12;
	setp.eq.s32 	%p98, %r668, 0;
	neg.f32 	%f586, %f585;
	selp.f32 	%f703, %f585, %f586, %p98;

$L__BB0_82:
	add.s32 	%r104, %r852, 1;
	and.b32  	%r105, %r104, 1;
	setp.eq.s32 	%p99, %r105, 0;
	selp.f32 	%f138, %f703, 0f3F800000, %p99;
	mul.rn.f32 	%f139, %f703, %f703;
	mov.f32 	%f704, 0fB94D4153;
	@%p99 bra 	$L__BB0_84;

	mov.f32 	%f665, 0fBAB607ED;
	mov.f32 	%f664, 0f37CBAC00;
	fma.rn.f32 	%f704, %f664, %f139, %f665;

$L__BB0_84:
	selp.f32 	%f591, 0f3C0885E4, 0f3D2AAABB, %p99;
	fma.rn.f32 	%f592, %f704, %f139, %f591;
	selp.f32 	%f593, 0fBE2AAAA8, 0fBEFFFFFF, %p99;
	fma.rn.f32 	%f594, %f592, %f139, %f593;
	fma.rn.f32 	%f596, %f139, %f138, %f192;
	fma.rn.f32 	%f705, %f594, %f596, %f138;
	and.b32  	%r673, %r104, 2;
	setp.eq.s32 	%p101, %r673, 0;
	@%p101 bra 	$L__BB0_86;

	mov.f32 	%f598, 0fBF800000;
	fma.rn.f32 	%f705, %f705, %f598, %f192;

$L__BB0_86:
	@%p92 bra 	$L__BB0_94;

	setp.eq.f32 	%p103, %f134, 0f7F800000;
	@%p103 bra 	$L__BB0_93;
	bra.uni 	$L__BB0_88;

$L__BB0_93:
	mul.rn.f32 	%f706, %f132, %f192;
	bra.uni 	$L__BB0_94;

$L__BB0_88:
	mov.b32 	%r106, %f132;
	bfe.u32 	%r674, %r106, 23, 8;
	add.s32 	%r107, %r674, -128;
	shl.b32 	%r675, %r106, 8;
	or.b32  	%r108, %r675, -2147483648;
	shr.u32 	%r109, %r107, 5;
	mov.u64 	%rd308, 0;
	mov.u64 	%rd307, %rd1;
	mov.u64 	%rd309, %rd308;

$L__BB0_89:
	.pragma "nounroll";
	shl.b64 	%rd243, %rd308, 2;
	mov.u64 	%rd244, __cudart_i2opi_f;
	add.s64 	%rd245, %rd244, %rd243;
	ld.global.nc.u32 	%r676, [%rd245];
	mad.wide.u32 	%rd246, %r676, %r108, %rd309;
	shr.u64 	%rd309, %rd246, 32;
	st.local.u32 	[%rd307], %rd246;
	cvt.u32.u64 	%r677, %rd308;
	add.s32 	%r678, %r677, 1;
	cvt.s64.s32 	%rd308, %r678;
	mul.wide.s32 	%rd247, %r678, 4;
	add.s64 	%rd307, %rd1, %rd247;
	setp.ne.s32 	%p104, %r678, 6;
	@%p104 bra 	$L__BB0_89;

	st.local.u32 	[%rd22], %rd309;
	mov.u32 	%r679, 4;
	sub.s32 	%r110, %r679, %r109;
	mov.u32 	%r680, 6;
	sub.s32 	%r681, %r680, %r109;
	mul.wide.s32 	%rd248, %r681, 4;
	add.s64 	%rd249, %rd1, %rd248;
	ld.local.u32 	%r853, [%rd249];
	ld.local.u32 	%r854, [%rd249+-4];
	and.b32  	%r113, %r107, 31;
	setp.eq.s32 	%p105, %r113, 0;
	@%p105 bra 	$L__BB0_92;

	mov.u32 	%r682, 32;
	sub.s32 	%r683, %r682, %r113;
	shr.u32 	%r684, %r854, %r683;
	shl.b32 	%r685, %r853, %r113;
	add.s32 	%r853, %r684, %r685;
	mul.wide.s32 	%rd250, %r110, 4;
	add.s64 	%rd251, %rd1, %rd250;
	ld.local.u32 	%r686, [%rd251];
	shr.u32 	%r687, %r686, %r683;
	shl.b32 	%r688, %r854, %r113;
	add.s32 	%r854, %r687, %r688;

$L__BB0_92:
	and.b32  	%r689, %r106, -2147483648;
	shr.u32 	%r690, %r854, 30;
	shl.b32 	%r691, %r853, 2;
	or.b32  	%r692, %r690, %r691;
	shr.u32 	%r693, %r692, 31;
	shr.u32 	%r694, %r853, 30;
	add.s32 	%r695, %r693, %r694;
	neg.s32 	%r696, %r695;
	setp.eq.s32 	%p106, %r689, 0;
	selp.b32 	%r855, %r695, %r696, %p106;
	setp.ne.s32 	%p107, %r693, 0;
	xor.b32  	%r697, %r689, -2147483648;
	selp.b32 	%r698, %r697, %r689, %p107;
	selp.b32 	%r699, -1, 0, %p107;
	xor.b32  	%r700, %r692, %r699;
	shl.b32 	%r701, %r854, 2;
	xor.b32  	%r702, %r701, %r699;
	cvt.u64.u32 	%rd252, %r700;
	cvt.u64.u32 	%rd253, %r702;
	bfi.b64 	%rd254, %rd252, %rd253, 32, 32;
	cvt.rn.f64.s64 	%fd13, %rd254;
	mul.f64 	%fd14, %fd13, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f599, %fd14;
	setp.eq.s32 	%p108, %r698, 0;
	neg.f32 	%f600, %f599;
	selp.f32 	%f706, %f599, %f600, %p108;

$L__BB0_94:
	mul.f32 	%f148, %f131, %f705;
	and.b32  	%r120, %r855, 1;
	setp.eq.s32 	%p109, %r120, 0;
	selp.f32 	%f149, %f706, 0f3F800000, %p109;
	mul.rn.f32 	%f150, %f706, %f706;
	mov.f32 	%f707, 0fB94D4153;
	@%p109 bra 	$L__BB0_96;

	mov.f32 	%f667, 0fBAB607ED;
	mov.f32 	%f666, 0f37CBAC00;
	fma.rn.f32 	%f707, %f666, %f150, %f667;

$L__BB0_96:
	selp.f32 	%f605, 0f3C0885E4, 0f3D2AAABB, %p109;
	fma.rn.f32 	%f606, %f707, %f150, %f605;
	selp.f32 	%f607, 0fBE2AAAA8, 0fBEFFFFFF, %p109;
	fma.rn.f32 	%f608, %f606, %f150, %f607;
	fma.rn.f32 	%f610, %f150, %f149, %f192;
	fma.rn.f32 	%f708, %f608, %f610, %f149;
	and.b32  	%r703, %r855, 2;
	setp.eq.s32 	%p111, %r703, 0;
	@%p111 bra 	$L__BB0_98;

	mov.f32 	%f612, 0fBF800000;
	fma.rn.f32 	%f708, %f708, %f612, %f192;

$L__BB0_98:
	abs.f32 	%f613, %f700;
	abs.f32 	%f614, %f702;
	setp.gt.f32 	%p112, %f614, %f613;
	neg.f32 	%f615, %f700;
	selp.f32 	%f710, %f702, %f615, %p112;
	neg.f32 	%f616, %f701;
	selp.f32 	%f709, %f616, 0f00000000, %p112;
	selp.f32 	%f711, 0f00000000, %f701, %p112;
	mul.f32 	%f617, %f711, %f711;
	fma.rn.f32 	%f618, %f710, %f710, %f617;
	fma.rn.f32 	%f159, %f709, %f709, %f618;
	setp.leu.f32 	%p113, %f159, 0f00000000;
	@%p113 bra 	$L__BB0_100;

	sqrt.rn.f32 	%f619, %f159;
	div.rn.f32 	%f709, %f709, %f619;
	div.rn.f32 	%f710, %f710, %f619;
	div.rn.f32 	%f711, %f711, %f619;

$L__BB0_100:
	mov.u32 	%r827, 1;
	mov.u32 	%r826, 255;
	mov.f32 	%f668, 0f5A0E1BCA;
	mov.u32 	%r825, 0;
	mul.f32 	%f629, %f131, %f708;
	mul.f32 	%f630, %f629, %f629;
	mul.f32 	%f631, %f148, %f148;
	sub.f32 	%f633, %f172, %f631;
	sub.f32 	%f634, %f633, %f630;
	max.f32 	%f635, %f192, %f634;
	sqrt.rn.f32 	%f636, %f635;
	mul.f32 	%f637, %f701, %f711;
	mul.f32 	%f638, %f700, %f710;
	sub.f32 	%f639, %f638, %f637;
	mul.f32 	%f640, %f700, %f709;
	mul.f32 	%f641, %f702, %f711;
	sub.f32 	%f642, %f641, %f640;
	mul.f32 	%f643, %f702, %f710;
	mul.f32 	%f644, %f701, %f709;
	sub.f32 	%f645, %f644, %f643;
	mul.f32 	%f646, %f148, %f639;
	fma.rn.f32 	%f647, %f629, %f709, %f646;
	fma.rn.f32 	%f623, %f702, %f636, %f647;
	mul.f32 	%f648, %f148, %f642;
	fma.rn.f32 	%f649, %f629, %f710, %f648;
	fma.rn.f32 	%f624, %f701, %f636, %f649;
	mul.f32 	%f650, %f148, %f645;
	fma.rn.f32 	%f651, %f629, %f711, %f650;
	fma.rn.f32 	%f625, %f700, %f636, %f651;
	mul.lo.s64 	%rd256, %rd62, 6364136223846793005;
	add.s64 	%rd316, %rd256, -2720673578348880933;
	// begin inline asm
	call(%r833,%r705,%r706,%r707,%r708,%r709,%r710,%r711,%r712,%r713,%r714,%r715,%r716,%r717,%r718,%r719,%r720,%r721,%r722,%r723,%r724,%r725,%r726,%r727,%r728,%r729,%r730,%r731,%r732,%r733,%r734,%r735),_optix_trace_typed_32,(%r825,%rd18,%f128,%f129,%f130,%f623,%f624,%f625,%f192,%f668,%f192,%r826,%r827,%r825,%r827,%r825,%r827,%r529,%r775,%r776,%r777,%r778,%r779,%r780,%r781,%r782,%r783,%r784,%r785,%r786,%r787,%r788,%r789,%r790,%r791,%r792,%r793,%r794,%r795,%r796,%r797,%r798,%r799,%r800,%r801,%r802,%r803,%r804,%r805);
	// end inline asm
	setp.eq.s32 	%p114, %r833, -1;
	@%p114 bra 	$L__BB0_110;

	mul.lo.s64 	%rd257, %rd316, 6364136223846793005;
	add.s64 	%rd78, %rd257, -2720673578348880933;
	shr.u64 	%rd258, %rd78, 18;
	xor.b64  	%rd259, %rd258, %rd78;
	shr.u64 	%rd260, %rd259, 27;
	cvt.u32.u64 	%r806, %rd260;
	shr.u64 	%rd261, %rd78, 59;
	cvt.u32.u64 	%r807, %rd261;
	shf.r.wrap.b32 	%r808, %r806, %r806, %r807;
	shr.u32 	%r809, %r808, 9;
	or.b32  	%r810, %r809, 1065353216;
	mov.b32 	%f652, %r810;
	add.f32 	%f653, %f652, 0fBF800000;
	mul.f32 	%f166, %f653, 0f40C90FDB;
	abs.f32 	%f654, %f166;
	setp.leu.f32 	%p115, %f654, 0f47CE4780;
	setp.eq.f32 	%p116, %f654, 0f7F800000;
	or.pred  	%p4, %p116, %p115;
	@%p4 bra 	$L__BB0_105;

	mov.b32 	%r811, %f166;
	shl.b32 	%r812, %r811, 8;
	or.b32  	%r122, %r812, -2147483648;
	mov.u64 	%rd311, 0;
	mov.u64 	%rd310, %rd1;
	mov.u64 	%rd312, %rd311;

$L__BB0_103:
	.pragma "nounroll";
	shl.b64 	%rd264, %rd311, 2;
	mov.u64 	%rd265, __cudart_i2opi_f;
	add.s64 	%rd266, %rd265, %rd264;
	ld.global.nc.u32 	%r813, [%rd266];
	mad.wide.u32 	%rd267, %r813, %r122, %rd312;
	shr.u64 	%rd312, %rd267, 32;
	st.local.u32 	[%rd310], %rd267;
	cvt.u32.u64 	%r814, %rd311;
	add.s32 	%r815, %r814, 1;
	cvt.s64.s32 	%rd311, %r815;
	mul.wide.s32 	%rd268, %r815, 4;
	add.s64 	%rd310, %rd1, %rd268;
	setp.ne.s32 	%p117, %r815, 6;
	@%p117 bra 	$L__BB0_103;

	st.local.u32 	[%rd22], %rd312;

$L__BB0_105:
	@%p4 bra 	$L__BB0_109;

	mov.b32 	%r816, %f166;
	shl.b32 	%r817, %r816, 8;
	or.b32  	%r123, %r817, -2147483648;
	mov.u64 	%rd314, 0;
	mov.u64 	%rd313, %rd1;
	mov.u64 	%rd315, %rd314;

$L__BB0_107:
	.pragma "nounroll";
	shl.b64 	%rd271, %rd314, 2;
	mov.u64 	%rd272, __cudart_i2opi_f;
	add.s64 	%rd273, %rd272, %rd271;
	ld.global.nc.u32 	%r818, [%rd273];
	mad.wide.u32 	%rd274, %r818, %r123, %rd315;
	shr.u64 	%rd315, %rd274, 32;
	st.local.u32 	[%rd313], %rd274;
	cvt.u32.u64 	%r819, %rd314;
	add.s32 	%r820, %r819, 1;
	cvt.s64.s32 	%rd314, %r820;
	mul.wide.s32 	%rd275, %r820, 4;
	add.s64 	%rd313, %rd1, %rd275;
	setp.ne.s32 	%p118, %r820, 6;
	@%p118 bra 	$L__BB0_107;

	st.local.u32 	[%rd22], %rd315;

$L__BB0_109:
	mul.lo.s64 	%rd276, %rd78, 6364136223846793005;
	add.s64 	%rd316, %rd276, -2720673578348880933;
	bra.uni 	$L__BB0_111;

$L__BB0_110:
	add.s32 	%r832, %r832, 1;
	setp.gt.u32 	%p119, %r832, 2;
	mov.u32 	%r833, -1;
	@%p119 bra 	$L__BB0_113;

$L__BB0_111:
	add.s32 	%r831, %r831, 1;
	setp.lt.u32 	%p120, %r831, 32;
	@%p120 bra 	$L__BB0_5;

	ld.const.u64 	%rd277, [params+16];
	cvta.to.global.u64 	%rd278, %rd277;
	shl.b64 	%rd279, %rd2, 2;
	add.s64 	%rd280, %rd278, %rd279;
	ld.global.f32 	%f655, [%rd280];
	neg.f32 	%f656, %f655;
	st.global.f32 	[%rd280], %f656;

$L__BB0_113:
	ret;

}
	// .globl	__miss__ms
.visible .entry __miss__ms()
{
	.reg .b32 	%r<3>;


	mov.u32 	%r1, 0;
	mov.u32 	%r2, -1;
	// begin inline asm
	call _optix_set_payload, (%r1, %r2);
	// end inline asm
	ret;

}
	// .globl	__closesthit__ch
.visible .entry __closesthit__ch()
{
	.reg .b32 	%r<4>;


	// begin inline asm
	call (%r1), _optix_read_primitive_idx, ();
	// end inline asm
	mov.u32 	%r2, 0;
	// begin inline asm
	call _optix_set_payload, (%r2, %r1);
	// end inline asm
	ret;

}

